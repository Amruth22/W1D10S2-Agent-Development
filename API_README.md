# ğŸš€ FastAPI + RabbitMQ Research Agent API

**Professional AI Research Assistant with Asynchronous Processing**

Transform your LangChain Research Agent into a **production-ready, scalable API service** with FastAPI and RabbitMQ integration.

## ğŸ¯ **Architecture Overview**

```
Client Request â†’ FastAPI â†’ RabbitMQ â†’ LangChain Agent â†’ Response
     â†“              â†“          â†“           â†“            â†“
   REST API    Queue Tasks  Process    Research     Store Results
```

### **Key Components:**
- **FastAPI**: High-performance REST API with automatic documentation
- **RabbitMQ**: Message queue for asynchronous task processing
- **LangChain Agent**: Your existing research agent (unchanged)
- **Redis**: Task result storage and caching
- **Docker**: Containerized deployment

## âœ¨ **Features**

### **ğŸ”¥ Production-Ready**
- âœ… **Asynchronous Processing** - Non-blocking API responses
- âœ… **Horizontal Scaling** - Multiple consumer workers
- âœ… **Message Persistence** - Reliable task queuing
- âœ… **Health Monitoring** - Built-in health checks
- âœ… **Auto Documentation** - Interactive API docs
- âœ… **Docker Support** - Easy deployment

### **ğŸ›ï¸ Advanced Capabilities**
- âœ… **Task Status Tracking** - Real-time progress updates
- âœ… **Priority Queues** - Urgent vs normal tasks
- âœ… **WebSocket Support** - Live status updates
- âœ… **File Generation** - Research reports with timestamps
- âœ… **Error Handling** - Robust failure management
- âœ… **CORS Support** - Cross-origin requests

## ğŸš€ **Quick Start**

### **1. Prerequisites**
```bash
# Install dependencies
pip install -r requirements.txt

# Install RabbitMQ (Ubuntu/Debian)
sudo apt-get install rabbitmq-server

# Or use Docker
docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.12-management
```

### **2. Configuration**
```bash
# Copy environment template
cp .env.example .env

# Edit configuration
nano .env
```

**Required Settings:**
```env
GEMINI_API_KEY=your-gemini-api-key-here
RABBITMQ_HOST=localhost
RABBITMQ_PORT=5672
```

### **3. Start the API**
```bash
# Method 1: Direct Python
python run_api.py server

# Method 2: Docker Compose (Recommended)
docker-compose up -d

# Method 3: Individual components
python run_api.py server    # Terminal 1: API Server
python run_api.py consumer  # Terminal 2: Task Consumer
```

### **4. Access the API**
- **API Server**: http://localhost:8000
- **Interactive Docs**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health
- **RabbitMQ Management**: http://localhost:15672 (guest/guest)

## ğŸ“š **API Usage Examples**

### **Submit Research Request**
```bash
curl -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Analyze the latest trends in quantum computing for 2024",
    "priority": "normal",
    "create_report": true,
    "include_sources": true
  }'
```

**Response:**
```json
{
  "task_id": "123e4567-e89b-12d3-a456-426614174000",
  "status": "queued",
  "message": "Research request submitted successfully",
  "estimated_time": "30-120 seconds"
}
```

### **Check Task Status**
```bash
curl "http://localhost:8000/research/123e4567-e89b-12d3-a456-426614174000/status"
```

**Response:**
```json
{
  "task_id": "123e4567-e89b-12d3-a456-426614174000",
  "status": "processing",
  "query": "Analyze the latest trends in quantum computing for 2024",
  "created_at": "2024-01-16T10:30:00",
  "progress": 50
}
```

### **Get Research Results**
```bash
curl "http://localhost:8000/research/123e4567-e89b-12d3-a456-426614174000"
```

**Response:**
```json
{
  "task_id": "123e4567-e89b-12d3-a456-426614174000",
  "status": "completed",
  "query": "Analyze the latest trends in quantum computing for 2024",
  "result": "Quantum computing is experiencing rapid advancement in 2024...",
  "created_at": "2024-01-16T10:30:00",
  "completed_at": "2024-01-16T10:32:15",
  "files_generated": ["quantum_computing_report_20240116_103215.md"]
}
```

## ğŸ **Python Client Example**

```python
import requests
import time

# Submit research request
response = requests.post("http://localhost:8000/research", json={
    "query": "Research the impact of AI on healthcare industry",
    "priority": "high",
    "create_report": True
})

task_data = response.json()
task_id = task_data["task_id"]
print(f"Task submitted: {task_id}")

# Poll for results
while True:
    status_response = requests.get(f"http://localhost:8000/research/{task_id}/status")
    status = status_response.json()
    
    print(f"Status: {status['status']} ({status['progress']}%)")
    
    if status["status"] in ["completed", "failed"]:
        break
    
    time.sleep(5)

# Get final results
if status["status"] == "completed":
    results_response = requests.get(f"http://localhost:8000/research/{task_id}")
    results = results_response.json()
    print(f"Research completed: {results['result'][:100]}...")
```

## ğŸ”§ **Advanced Configuration**

### **Environment Variables**
```env
# Production Settings
ENVIRONMENT=production
DEBUG=false
REQUIRE_API_KEY=true
ALLOWED_API_KEYS=key1,key2,key3

# Scaling Settings
MAX_CONCURRENT_TASKS=50
TASK_TIMEOUT_SECONDS=600

# RabbitMQ Clustering
RABBITMQ_HOST=rabbitmq-cluster.example.com
RABBITMQ_USERNAME=research_user
RABBITMQ_PASSWORD=secure_password
```

### **Docker Compose Production**
```bash
# Start with production profile
docker-compose --profile production up -d

# Scale consumers
docker-compose up -d --scale consumer=5

# View logs
docker-compose logs -f api consumer
```

## ğŸ“Š **API Endpoints**

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | API information |
| `GET` | `/health` | Health check |
| `POST` | `/research` | Submit research request |
| `GET` | `/research/{task_id}` | Get research results |
| `GET` | `/research/{task_id}/status` | Get task status |
| `GET` | `/research` | List all tasks |
| `DELETE` | `/research/{task_id}` | Cancel task |
| `WS` | `/ws/{task_id}` | WebSocket status updates |

## ğŸ—ï¸ **Architecture Benefits**

### **ğŸš€ Scalability**
- **Horizontal Scaling**: Add more consumer workers
- **Load Distribution**: RabbitMQ distributes tasks evenly
- **Resource Isolation**: API and processing separated

### **ğŸ”’ Reliability**
- **Message Persistence**: Tasks survive system restarts
- **Error Recovery**: Failed tasks can be retried
- **Health Monitoring**: Built-in health checks

### **âš¡ Performance**
- **Non-blocking**: API responds immediately
- **Concurrent Processing**: Multiple tasks simultaneously
- **Efficient Queuing**: RabbitMQ handles high throughput

### **ğŸ› ï¸ Maintainability**
- **Modular Design**: Clear separation of concerns
- **Docker Support**: Easy deployment and scaling
- **Configuration Management**: Environment-based config

## ğŸ” **Monitoring & Debugging**

### **RabbitMQ Management UI**
- **URL**: http://localhost:15672
- **Credentials**: guest/guest (development)
- **Features**: Queue monitoring, message tracking, performance metrics

### **Health Checks**
```bash
# API Health
curl http://localhost:8000/health

# RabbitMQ Health
curl http://localhost:15672/api/healthchecks/node

# Container Health
docker-compose ps
```

### **Logs**
```bash
# API Logs
docker-compose logs -f api

# Consumer Logs
docker-compose logs -f consumer

# RabbitMQ Logs
docker-compose logs -f rabbitmq
```

## ğŸš¨ **Troubleshooting**

### **Common Issues**

**1. RabbitMQ Connection Failed**
```bash
# Check RabbitMQ status
sudo systemctl status rabbitmq-server

# Restart RabbitMQ
sudo systemctl restart rabbitmq-server

# Check Docker container
docker-compose logs rabbitmq
```

**2. Tasks Stuck in Queue**
```bash
# Check consumer status
docker-compose logs consumer

# Restart consumers
docker-compose restart consumer

# Check queue status in RabbitMQ UI
```

**3. API Not Responding**
```bash
# Check API logs
docker-compose logs api

# Verify port binding
netstat -tlnp | grep 8000

# Test health endpoint
curl http://localhost:8000/health
```

## ğŸ” **Security Considerations**

### **Production Security**
```env
# Enable API key authentication
REQUIRE_API_KEY=true
ALLOWED_API_KEYS=your-secure-api-key

# Restrict CORS origins
CORS_ORIGINS=https://yourdomain.com

# Use secure RabbitMQ credentials
RABBITMQ_USERNAME=secure_user
RABBITMQ_PASSWORD=complex_password
```

### **Network Security**
- Use HTTPS in production
- Implement rate limiting
- Set up firewall rules
- Use VPN for internal services

## ğŸ“ˆ **Performance Tuning**

### **Scaling Guidelines**
- **API Instances**: 1-2 per CPU core
- **Consumer Workers**: 2-4 per CPU core
- **RabbitMQ**: Dedicated server for high load
- **Redis**: Use Redis Cluster for large datasets

### **Optimization Tips**
```python
# Increase worker processes
uvicorn.run("api.main:app", workers=4)

# Tune RabbitMQ prefetch
await channel.set_qos(prefetch_count=10)

# Use connection pooling
# Implement result caching
```

## ğŸ¯ **Use Cases**

### **Perfect For:**
- **Research Platforms** - Academic and commercial research
- **Content Generation** - Automated report creation
- **Data Analysis** - Large-scale information processing
- **Microservices** - Part of larger application ecosystem
- **API Services** - Expose research capabilities to other systems

### **Example Applications:**
- Market research automation
- Academic paper analysis
- Competitive intelligence
- Content creation pipelines
- Business intelligence systems

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open Pull Request

## ğŸ“„ **License**

This project is licensed under the MIT License - see the LICENSE file for details.

---

**ğŸš€ Transform your research agent into a production-ready API service!**

*Built with FastAPI, RabbitMQ, and LangChain for maximum performance and scalability.*